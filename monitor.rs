#![allow(unused_imports)]

use std::fs;
use std::str::FromStr;
use colored::Colorize;
use anyhow::{Result, anyhow};
use log;
use reqwest;
use serde::{Deserialize, Serialize};
use log4rs::config::LevelFilter;
use lru::LruCache;
use dashmap::DashMap;
use futures::future::join_all;
use std::num::NonZeroUsize;
use std::sync::atomic::{AtomicUsize, AtomicF64, AtomicBool, Ordering, AtomicU64};
use std::future::Future;
use atomic_float::AtomicF64;
use chrono::{DateTime, Local};
use solana_client::rpc_client::RpcClient;
use solana_sdk::{commitment_config::CommitmentConfig, pubkey::Pubkey};
use solana_transaction_status::{
    EncodedConfirmedBlock,
    EncodedTransaction,
    UiTransactionEncoding,
};
use std::{
    collections::{HashMap, HashSet},
    sync::Arc,
    time::{Duration, SystemTime, Instant, UNIX_EPOCH, DateTime, Local},
    io::Read,
    process,
    path::Path,
    path::PathBuf,
};
use tokio::{
    sync::{mpsc, Mutex},
    time,
};
use log4rs::{
    append::rolling_file::{
        RollingFileAppender, 
        policy::compound::{
            CompoundPolicy,
            trigger::size::SizeTrigger,
            roll::fixed_window::FixedWindowRoller,
        },
    },
    config::{Appender, Config, Root},
    encode::pattern::PatternEncoder,
};
use log4rs::append::console::ConsoleAppender;

#[derive(Debug, Clone)]
struct AppConfig {
    api_keys: Vec<String>,
    serverchan: ServerChanConfig,
    wcf: WeChatFerryConfig,
    proxy: ProxyConfig,
    rpc_nodes: HashMap<String, RpcNodeConfig>,
}

impl AppConfig {
    fn builder() -> ConfigBuilder {
        ConfigBuilder::default()
    }
}

#[derive(Default)]
struct ConfigBuilder {
    api_keys: Vec<String>,
    serverchan: Option<ServerChanConfig>,
    wcf: Option<WeChatFerryConfig>,
    proxy: Option<ProxyConfig>,
    rpc_nodes: HashMap<String, RpcNodeConfig>,
}

impl ConfigBuilder {
    fn api_key(mut self, key: String) -> Self {
        self.api_keys.push(key);
        self
    }

    fn serverchan(mut self, config: ServerChanConfig) -> Self {
        self.serverchan = Some(config);
        self
    }

    fn wcf(mut self, config: WeChatFerryConfig) -> Self {
        self.wcf = Some(config);
        self
    }

    fn proxy(mut self, config: ProxyConfig) -> Self {
        self.proxy = Some(config);
        self
    }

    fn rpc_node(mut self, url: String, config: RpcNodeConfig) -> Self {
        self.rpc_nodes.insert(url, config);
        self
    }

    fn build(self) -> Result<AppConfig> {
        Ok(AppConfig {
            api_keys: self.api_keys,
            serverchan: self.serverchan.unwrap_or_default(),
            wcf: self.wcf.unwrap_or_default(),
            proxy: self.proxy.unwrap_or_default(),
            rpc_nodes: self.rpc_nodes,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ServerChanConfig {
    keys: Vec<String>,
    alert_interval: u64,  // æ–°å¢
    heartbeat_interval: u64,  // æ–°å¢
}

impl Default for ServerChanConfig {
    fn default() -> Self {
        Self {
            keys: Vec::new(),
            alert_interval: 300,
            heartbeat_interval: 3600,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct WeChatFerryConfig {
    groups: Vec<WeChatGroup>,
}

impl Default for WeChatFerryConfig {
    fn default() -> Self {
        Self {
            groups: Vec::new(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct WeChatGroup {
    name: String,
    wxid: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProxyConfig {
    pub id: String,           // æ–°å¢
    pub name: String,         // æ–°å¢
    pub ip: String,
    pub port: u16,
    pub username: String,
    pub password: String,
    pub protocol: ProxyProtocol,  // æ–°å¢
    pub enabled: bool,
    pub last_check: SystemTime,   // æ–°å¢
    pub status: ProxyStatus,      // æ–°å¢
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ProxyProtocol {
    Http,
    Https,
    Socks5,
}

impl ProxyProtocol {
    fn as_str(&self) -> &'static str {
        match self {
            ProxyProtocol::Http => "http",
            ProxyProtocol::Https => "https",
            ProxyProtocol::Socks5 => "socks5",
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ProxyStatus {
    Active,
    Inactive,
    Failed,
}

pub struct ProxyManager {
    proxies: Arc<DashMap<String, ProxyConfig>>,
    config_file: PathBuf,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct RpcNodeConfig {
    pub id: String,
    pub name: String,
    pub url: String,
    pub weight: f64,
    pub enabled: bool,
    pub is_default: bool,
    pub last_check: SystemTime,
    pub status: RpcStatus,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RpcStatus {
    Healthy,
    Unhealthy,
    Unknown,
}

pub struct RpcManager {
    nodes: Arc<DashMap<String, RpcNodeConfig>>,
    config_file: PathBuf,
    default_nodes: Vec<RpcNodeConfig>,
}

#[derive(Debug)]
struct Metrics {
    processed_blocks: u64,
    processed_txs: u64,
    missed_blocks: HashSet<u64>,
    processing_delays: Vec<Duration>,
    last_process_time: Instant,
    retry_counts: AtomicUsize,
}

impl Default for Metrics {
    fn default() -> Self {
        Self {
            processed_blocks: 0,
            processed_txs: 0,
            missed_blocks: HashSet::new(),
            processing_delays: Vec::new(),
            last_process_time: Instant::now(),
            retry_counts: AtomicUsize::new(0),
        }
    }
}

struct RpcPool {
    clients: Vec<Arc<RpcClient>>,
    health_status: DashMap<String, bool>,
    current_index: AtomicUsize,
    metrics: Arc<RpcMetrics>,
}

impl RpcPool {
    async fn get_healthy_client(&self) -> Option<Arc<RpcClient>> {
        let start_idx = self.current_index.fetch_add(1, Ordering::Relaxed);
        for i in 0..self.clients.len() {
            let idx = (start_idx + i) % self.clients.len();
            if let Some(status) = self.health_status.get(&self.clients[idx].url()) {
                if *status {
                    self.current_index.store(idx, Ordering::Relaxed);
                    return Some(self.clients[idx].clone());
                }
            }
        }
        None
    }
}

//===========================================
// ç¼“å­˜ç³»ç»Ÿæ¨¡å—
//===========================================
struct CacheSystem {
    blocks: DashMap<u64, EncodedConfirmedBlock>,
    token_info: LruCache<Pubkey, (TokenInfo, SystemTime)>,
    creator_history: DashMap<Pubkey, (CreatorHistory, SystemTime)>,
    fund_flow: DashMap<Pubkey, (Vec<FundingChain>, SystemTime)>,
    transactions: LruCache<String, EncodedTransaction>,
}

impl CacheSystem {
    fn new() -> Self {
        Self {
            blocks: DashMap::new(),
            token_info: LruCache::new(NonZeroUsize::new(100).unwrap()),
            creator_history: DashMap::new(),
            fund_flow: DashMap::new(),
            transactions: LruCache::new(NonZeroUsize::new(100).unwrap()),
        }
    }

    async fn cleanup(&mut self) {
        // ä»…ä¿ç•™æœ€è¿‘1å°æ—¶çš„åŒºå—æ•°æ®ï¼Œå…¶ä»–ç¼“å­˜é¡¹ä½¿ç”¨LRUè‡ªåŠ¨æ¸…ç†
        let now = SystemTime::now();
        self.blocks.retain(|_, v| {
            v.block_time
                .map(|t| now.duration_since(UNIX_EPOCH).unwrap().as_secs() - t < 3600)
                .unwrap_or(false)
        });
    }
}

//===========================================
// æ—¥å¿—ç³»ç»Ÿæ¨¡å—
//===========================================
struct AsyncLogger {
    sender: mpsc::Sender<LogMessage>,
}

#[derive(Debug)]
struct LogMessage {
    level: log::Level,
    content: String,
    timestamp: SystemTime,
}

impl AsyncLogger {
    async fn new() -> Result<Self> {
        let (tx, mut rx) = mpsc::channel(1000);
        
        // å¯åŠ¨æ—¥å¿—å¤„ç†çº¿ç¨‹
        tokio::spawn(async move {
            while let Some(msg) = rx.recv().await {
                let level_str = match msg.level {
                    log::Level::Error => "ERROR".red(),
                    log::Level::Warn => "WARN".yellow(),
                    log::Level::Info => "INFO".green(),
                    log::Level::Debug => "DEBUG".blue(),
                    log::Level::Trace => "TRACE".normal(),
                };

                println!(
                    "{} [{}] {}",
                    chrono::DateTime::<chrono::Local>::from(msg.timestamp)
                        .format("%Y-%m-%d %H:%M:%S"),
                    level_str,
                    msg.content
                );
            }
        });

        Ok(Self { sender: tx })
    }

    async fn log(&self, level: log::Level, message: impl Into<String>) {
        if let Err(e) = self.sender.send(LogMessage {
            level,
            content: message.into(),
            timestamp: SystemTime::now(),
        }).await {
            eprintln!("Failed to send log: {}", e);
        }
    }
}

//===========================================
// ç›‘æ§çŠ¶æ€ç®¡ç†æ¨¡å—
//===========================================
#[derive(Debug, Default, Serialize, Deserialize)]
struct MonitorState {
    last_slot: u64,
    processed_blocks: u64,
    processed_tokens: u64,
    alerts: Vec<Alert>,
    watch_addresses: HashSet<String>,
    metrics: MonitorMetrics,
    start_time: SystemTime,
}

#[derive(Debug, Serialize, Deserialize)]
struct Alert {
    timestamp: SystemTime,
    level: AlertLevel,
    message: String,
    token_info: Option<TokenInfo>,
}

#[derive(Debug, Serialize, Deserialize)]
enum AlertLevel {
    High,
    Medium,
    Low,
}

#[derive(Debug, Default, Serialize, Deserialize)]
struct MonitorMetrics {
    uptime: Duration,
    cpu_usage: f64,
    memory_usage: f64,
    rpc_requests: u64,
    rpc_errors: u64,
}

//===========================================
// æ™ºèƒ½æ‰¹å¤„ç†æ¨¡å—
//===========================================
struct SmartBatcher {
    batch_size: AtomicUsize,
    load_metrics: Arc<LoadMetrics>,
    pending_requests: Arc<AtomicUsize>,
}

impl SmartBatcher {
    fn new() -> Self {
        Self {
            batch_size: AtomicUsize::new(TokenMonitor::BLOCK_BATCH_SIZE),
            load_metrics: Arc::new(LoadMetrics::default()),
            pending_requests: Arc::new(AtomicUsize::new(0)),
        }
    }

    fn adjust_batch_size(&self) {
        let cpu_usage = self.load_metrics.cpu_usage.load(Ordering::Relaxed);
        let memory_usage = self.load_metrics.memory_usage.load(Ordering::Relaxed);
        let pending = self.pending_requests.load(Ordering::Relaxed);
        
        let current_size = self.batch_size.load(Ordering::Relaxed);
        let mut new_size = current_size;

        // CPUè´Ÿè½½è°ƒæ•´
        if cpu_usage > 80.0 {
            new_size = (current_size as f64 * 0.8) as usize;
        } else if cpu_usage < 50.0 && pending < TokenMonitor::MAX_PENDING_REQUESTS / 2 {
            new_size = (current_size as f64 * 1.2) as usize;
        }

        // å†…å­˜è´Ÿè½½è°ƒæ•´
        if memory_usage > 80.0 {
            new_size = (new_size as f64 * 0.8) as usize;
        }

        // ç¡®ä¿æ‰¹å¤„ç†å¤§å°åœ¨åˆç†èŒƒå›´å†…
        new_size = new_size.max(10).min(1000);
        
        self.batch_size.store(new_size, Ordering::Relaxed);
    }

    async fn process_batch<T, F, Fut>(&self, items: Vec<T>, process_fn: F) -> Result<()>
    where
        F: Fn(T) -> Fut,
        Fut: Future<Output = Result<()>>,
    {
        let batch_size = self.batch_size.load(Ordering::Relaxed);
        
        for chunk in items.chunks(batch_size) {
            let futures: Vec<_> = chunk
                .iter()
                .map(|item| process_fn(item.clone()))
                .collect();
                
            self.pending_requests.fetch_add(futures.len(), Ordering::Relaxed);
            
            join_all(futures).await
                .into_iter()
                .collect::<Result<Vec<_>>>()?;
                
            self.pending_requests.fetch_sub(futures.len(), Ordering::Relaxed);
            
            // åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°
            self.adjust_batch_size();
        }
        
        Ok(())
    }
}

struct TokenMonitor {
    config: AppConfig,
    rpc_pool: Arc<RpcPool>,
    cache: Arc<Mutex<CacheSystem>>,
    logger: Arc<AsyncLogger>,
    batcher: Arc<SmartBatcher>,
    metrics: Arc<Mutex<Metrics>>,
    pump_program: Pubkey,
    client: reqwest::Client,
    current_api_key: Arc<Mutex<usize>>,
    request_counts: DashMap<String, u32>,
    last_reset: DashMap<String, SystemTime>,
    watch_addresses: HashSet<String>,
    monitor_state: Arc<Mutex<MonitorState>>,
    proxy_pool: Arc<Mutex<ProxyPool>>,
    // æ·»åŠ æœåŠ¡çŠ¶æ€ç®¡ç†
    service_state: Arc<ServiceState>,
    last_alert: tokio::sync::Mutex<SystemTime>,
}

impl Clone for TokenMonitor {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            rpc_pool: self.rpc_pool.clone(),
            cache: self.cache.clone(),
            logger: self.logger.clone(),
            batcher: self.batcher.clone(),
            metrics: self.metrics.clone(),
            pump_program: self.pump_program,
            client: self.client.clone(),
            current_api_key: self.current_api_key.clone(),
            request_counts: self.request_counts.clone(),
            last_reset: self.last_reset.clone(),
            watch_addresses: self.watch_addresses.clone(),
            monitor_state: self.monitor_state.clone(),
            proxy_pool: self.proxy_pool.clone(),
            service_state: self.service_state.clone(),
            last_alert: tokio::sync::Mutex::new(SystemTime::now()),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct FundingChain {
    total_amount: f64,
    transfers: Vec<Transfer>,
    risk_level: u8,
    source_wallet: String,
    intermediate_wallet: String,
    destination_wallet: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Transfer {
    source: Pubkey,
    amount: f64,
    timestamp: u64,
    success_tokens: Option<Vec<TokenInfo>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct TokenInfo {
    mint: Pubkey,
    name: String,
    symbol: String,
    market_cap: f64,
    liquidity: f64,
    holder_count: u64,
    holder_concentration: f64,
    verified: bool,
    price: f64,
    supply: u64,
    creator: Pubkey,
}

#[derive(Debug, Default)]
struct ProxyPool {
    proxies: Vec<ProxyConfig>,
    current_index: usize,
    last_check: SystemTime,
    health_status: DashMap<String, bool>, // æ–°å¢å¥åº·çŠ¶æ€è¿½è¸ª
}

impl ProxyPool {
    fn new(proxies: Vec<ProxyConfig>) -> Self {
        Self {
            proxies,
            current_index: 0,
            last_check: SystemTime::now(),
            health_status: DashMap::new(),
        }
    }

    async fn get_next_proxy(&mut self) -> Option<reqwest::Proxy> {
        if self.proxies.is_empty() {
            return None;
        }

        let proxy = &self.proxies[self.current_index];
        self.current_index = (self.current_index + 1) % self.proxies.len();
        
        let protocol_str = proxy.protocol.as_str();
        
        let proxy_url = format!(
            "{}://{}:{}@{}:{}",
            protocol_str,
            proxy.username,
            proxy.password,
            proxy.ip,
            proxy.port
        );

        match proxy.protocol {
            ProxyProtocol::Socks5 => reqwest::Proxy::all(&proxy_url).ok(),
            _ => reqwest::Proxy::http(&proxy_url).ok(),
        }
    }

    async fn check_proxies(&mut self) {
        if self.proxies.is_empty() {
            log::warn!("ä»£ç†æ± ä¸ºç©ºï¼Œè·³è¿‡å¥åº·æ£€æŸ¥");
            return;
        }

        let now = SystemTime::now();
        let mut working_proxies = Vec::new();
        
        for proxy in &self.proxies {
            let result = self.test_proxy(proxy).await;
            match result {
                Ok(true) => working_proxies.push(proxy.clone()),
                Ok(false) => log::warn!("ä»£ç† {} æ£€æµ‹å¤±è´¥", proxy.id),
                Err(e) => log::error!("ä»£ç†æ£€æµ‹é”™è¯¯: {}", e),
            }
        }
        
        self.proxies = working_proxies;
        self.current_index = 0;
    }

    pub async fn maintain(&mut self) {
        if self.proxies.is_empty() {
            return;
        }
        let now = SystemTime::now();
        if now.duration_since(self.last_check).unwrap().as_secs() > 300 {
            self.check_proxies().await;
            self.last_check = now;
        }
    }

    async fn test_proxy(&self, proxy: &ProxyConfig) -> Result<bool> {
        let client = reqwest::Client::builder()
            .proxy(self.build_proxy(proxy)?)
            .timeout(Duration::from_secs(5))
            .build()?;
            
        let response = client.get("https://api.mainnet-beta.solana.com")
            .send()
            .await?;
            
        let is_healthy = response.status().is_success();
        self.health_status.insert(proxy.id.clone(), is_healthy);
        
        Ok(is_healthy)
    }
}

impl TokenMonitor {
    const BLOCK_BATCH_SIZE: usize = 100;
    const MAX_PENDING_REQUESTS: usize = 1000;
    const WORKER_THREADS: usize = 20;

    fn get_proxy(config: &ProxyConfig) -> Option<reqwest::Proxy> {
        if !config.enabled {
            return None;
        }

        let proxy_url = format!(
            "http://{}:{}@{}:{}",
            config.username,
            config.password,
            config.ip,
            config.port
        );

        reqwest::Proxy::http(&proxy_url).ok()
    }

    async fn new() -> Result<Self> {
        // åˆå§‹åŒ–æ—¥å¿—
        Self::init_logger()?;
        
        log::info!("Starting Solana Token Monitor...");
        
        let config = Self::load_config()?;
        
        let proxy_pool = if config.proxy.enabled {
            let proxies = Self::load_proxy_list()?;
            Arc::new(Mutex::new(ProxyPool::new(proxies)))
        } else {
            Arc::new(Mutex::new(ProxyPool::default()))
        };

        let mut client_builder = reqwest::Client::builder();
        if let Some(proxy) = Self::get_proxy(&config.proxy) {
            client_builder = client_builder.proxy(proxy);
        }
        let client = client_builder.build()?;

        let mut monitor = Self {
            config: config.clone(),
            rpc_pool: Arc::new(RpcPool {
                clients: Vec::new(),
                health_status: DashMap::new(),
                current_index: AtomicUsize::new(0),
                metrics: Arc::new(RpcMetrics::default()),
            }),
            cache: Arc::new(Mutex::new(CacheSystem::new())),
            logger: Arc::new(AsyncLogger {
                sender: mpsc::channel(1000).0,
            }),
            batcher: Arc::new(SmartBatcher::new()),
            metrics: Arc::new(Mutex::new(Metrics::default())),
            pump_program: "6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ35MKDfgCcMKJ".parse()?,
            client,
            current_api_key: Arc::new(Mutex::new(0)),
            request_counts: DashMap::new(),
            last_reset: DashMap::new(),
            watch_addresses: HashSet::new(),
            monitor_state: Arc::new(Mutex::new(MonitorState::default())),
            proxy_pool,
            service_state: Arc::new(ServiceState::new()),
            last_alert: tokio::sync::Mutex::new(SystemTime::now()),
        };

        monitor.init_rpc_nodes();
        
        let metrics = monitor.metrics.clone();
        tokio::spawn(async move {
            Self::collect_metrics(metrics).await;
        });

        let watch_addresses = Self::load_watch_addresses()?;
        
        let monitor_state = Self::load_monitor_state()?;
        
        Ok(Self {
            config,
            rpc_pool: monitor.rpc_pool,
            cache: monitor.cache,
            logger: monitor.logger,
            batcher: monitor.batcher,
            metrics: monitor.metrics,
            pump_program: monitor.pump_program,
            client: monitor.client,
            current_api_key: monitor.current_api_key,
            request_counts: monitor.request_counts,
            last_reset: monitor.last_reset,
            watch_addresses,
            monitor_state: Arc::new(Mutex::new(monitor_state)),
            proxy_pool: monitor.proxy_pool,
            service_state: monitor.service_state,
            last_alert: tokio::sync::Mutex::new(SystemTime::now()),
        })
    }

    fn init_rpc_nodes(&mut self) {
        let default_nodes = vec![
            "https://api.mainnet-beta.solana.com",
            "https://api.metaplex.solana.com",
            "https://solana-api.projectserum.com",
            "https://ssc-dao.genesysgo.net",
            "https://rpc.ankr.com/solana",
        ];

        for url in default_nodes {
            self.rpc_pool.clients.push(Arc::new(RpcClient::new_with_commitment(
                url.to_string(),
                CommitmentConfig::confirmed(),
            )));
        }
    }

    async fn collect_metrics(metrics: Arc<Mutex<Metrics>>) {
        loop {
            let mut metrics = metrics.lock().await;
            let duration = metrics.last_process_time.elapsed();
            
            let blocks_per_second = metrics.processed_blocks as f64 / duration.as_secs_f64();
            let txs_per_second = metrics.processed_txs as f64 / duration.as_secs_f64();
            
            let avg_delay = if !metrics.processing_delays.is_empty() {
                metrics.processing_delays.iter()
                    .map(|d| d.as_millis() as f64)
                    .sum::<f64>() / metrics.processing_delays.len() as f64
            } else {
                0.0
            };

            log::info!(
                "æ€§èƒ½æŒ‡æ ‡ - åŒºå—å¤„ç†é€Ÿåº¦: {:.2}/s, äº¤æ˜“å¤„ç†é€Ÿåº¦: {:.2}/s, å¹³å‡å»¶è¿Ÿ: {:.2}ms, ä¸¢å¤±åŒºå—: {}",
                blocks_per_second,
                txs_per_second,
                avg_delay,
                metrics.missed_blocks.len()
            );

            metrics.processed_blocks = 0;
            metrics.processed_txs = 0;
            metrics.processing_delays.clear();
            metrics.last_process_time = Instant::now();

            if !metrics.missed_blocks.is_empty() {
                log::info!("å‘ç° {} ä¸ªä¸¢å¤±åŒºå—ï¼Œå°è¯•é‡æ–°å¤„ç†", metrics.missed_blocks.len());
            }

            drop(metrics);
            time::sleep(Duration::from_secs(60)).await;
        }
    }

    async fn start_worker_threads(
        &self,
        mut block_rx: mpsc::Receiver<u64>,
        token_tx: mpsc::Sender<(Pubkey, Pubkey)>,
    ) -> Result<()> {
        let monitor = Arc::new(self.clone());
        
        for _ in 0..Self::WORKER_THREADS {
            let monitor = monitor.clone();
            let token_tx = token_tx.clone();
            
            tokio::spawn(async move {
                while let Some(slot) = block_rx.recv().await {
                    if let Err(e) = monitor.process_block(slot, &token_tx).await {
                        log::error!("Error processing block {}: {}", slot, e);
                    }
                }
            });
        }
        
        Ok(())
    }

    fn load_config() -> Result<AppConfig> {
        let config_path = dirs::home_dir()
            .ok_or_else(|| anyhow!("Cannot find home directory"))?
            .join(".solana_pump")
            .join("config.json");

        let config_str = fs::read_to_string(config_path)?;
        Ok(serde_json::from_str(&config_str)?)
    }

    async fn start(&mut self) -> Result<()> {
        log::info!("Starting Solana token monitor...");
        self.start_heartbeat().await; // å¯åŠ¨å¿ƒè·³ä»»åŠ¡
        
        let (block_tx, block_rx) = mpsc::channel(1000);
        let (token_tx, token_rx) = mpsc::channel(1000);
        
        self.start_worker_threads(block_rx, token_tx).await?;
        self.monitor_blocks(block_tx).await
    }

    async fn monitor_blocks(&self, block_tx: mpsc::Sender<u64>) -> Result<()> {
        let mut last_slot = 0u64;
        
        loop {
            let start_time = Instant::now();
            
            match self.get_current_slot().await {
                Ok(current_slot) => {
                    if current_slot > last_slot {
                        for slot in (last_slot + 1)..=current_slot {
                            block_tx.send(slot).await?;
                        }
                        last_slot = current_slot;
                    }
                }
                Err(e) => {
                    log::error!("Failed to get current slot: {}", e);
                    time::sleep(Duration::from_secs(1)).await;
                    continue;
                }
            }

            let mut metrics = self.metrics.lock().await;
            metrics.processing_delays.push(start_time.elapsed());
            let retries_remaining = 3 - retries_used;
            metrics.retry_counts.fetch_add(retries_remaining as usize, Ordering::Relaxed);
            
            time::sleep(Duration::from_millis(20)).await;
        }
    }

    async fn get_current_slot(&self) -> Result<u64> {
        for client in &self.rpc_pool.clients {
            match client.get_slot().await {
                Ok(slot) => return Ok(slot),
                Err(e) => log::warn!("RPC client error: {}", e),
            }
        }
        Err(anyhow!("All RPC clients failed"))
    }

    async fn process_block(&self, slot: u64, token_tx: &mpsc::Sender<(Pubkey, Pubkey)>) -> Result<()> {
        let mut retries = 3;
        while retries > 0 {
            match self.get_block(slot).await {
                Ok(Some(block)) => {
                    log::info!("æˆåŠŸè·å–åŒºå— {} (ç»è¿‡ {} æ¬¡é‡è¯•)", slot, 3 - retries);
                    for tx in block.transactions {
                        if let Some((mint, creator)) = self.extract_pump_info(&tx) {
                            token_tx.send((mint, creator)).await?;
                            let mut metrics = self.metrics.lock().await;
                            metrics.processed_txs += 1;
                        }
                    }

                    let mut metrics = self.metrics.lock().await;
                    metrics.processed_blocks += 1;
                    let retry_count = 3 - retries;
                    metrics.retry_counts.fetch_add(retry_count as usize, Ordering::Relaxed);
                    return Ok(());
                },
                Err(e) => {
                    if retries == 1 { // æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥
                        self.send_alert(
                            "åŒºå—è·å–å¤±è´¥", 
                            &format!("æ— æ³•è·å–åŒºå— {}\né”™è¯¯: {}\næœ€åå°è¯•æ—¶é—´: {}", 
                                slot, e, chrono::Local::now().format("%H:%M:%S"))
                        ).await;
                    }
                    log::warn!("è·å–åŒºå— {} å¤±è´¥ (å‰©ä½™é‡è¯•æ¬¡æ•°: {}): {}", slot, retries-1, e);
                    log::debug!("é”™è¯¯é“¾: {:?}", e.chain().collect::<Vec<_>>());
                    retries -= 1;
                    tokio::time::sleep(Duration::from_secs(1 << (3 - retries))).await;
                }
            }
        }
        Err(anyhow!("æ— æ³•è·å–åŒºå— {} ç»è¿‡3æ¬¡é‡è¯•", slot))
    }

    async fn get_block(&self, slot: u64) -> Result<Option<EncodedConfirmedBlock>> {
        let mut last_error = None;
        for client in &self.rpc_pool.clients {
            match client.get_block_with_encoding(
                slot,
                UiTransactionEncoding::Json,
            ).await {
                Ok(block) => return Ok(Some(block)),
                Err(e) => {
                    log::warn!("RPC client error: {}", e);
                    last_error = Some(e);
                }
            }
        }
        if let Some(e) = last_error {
            Err(anyhow!("All RPC clients failed: {}", e))
        } else {
            Ok(None)
        }
    }

    fn extract_pump_info(&self, tx: &EncodedTransaction) -> Option<(Pubkey, Pubkey)> {
        let message = &tx.message;
        
        if !message.account_keys.contains(&self.pump_program) {
            return None;
        }
        
        Some((
            message.account_keys[4],
            message.account_keys[0],
        ))
    }

    async fn get_next_api_key(&self) -> String {
        let mut current = self.current_api_key.lock().await;
        let key = &self.config.api_keys[*current];
        
        let now = SystemTime::now();
        let request_count = self.request_counts.get(key).unwrap_or(&0);
        let last_reset = self.last_reset.get(key).unwrap_or(&now);
        
        if last_reset.elapsed().unwrap().as_secs() >= 60 {
            self.request_counts.insert(key.clone(), 0);
            self.last_reset.insert(key.clone(), now);
        } else if *request_count >= 60 {
            time::sleep(Duration::from_secs(1)).await;
        }
        
        self.request_counts.insert(key.clone(), request_count + 1);
        
        *current = (*current + 1) % self.config.api_keys.len();
        
        key.clone()
    }

    async fn analyze_token(&self, mint: &Pubkey, creator: &Pubkey) -> Result<TokenAnalysis> {
        let (token_info, creator_history, fund_flow) = tokio::join!(
            self.fetch_token_info(mint),
            self.analyze_creator_history(creator),
            self.trace_fund_flow(creator)
        );

        let token_info = token_info?;
        let creator_history = creator_history?;
        let fund_flow = fund_flow?.to_vec();
        
        let risk_score = self.calculate_risk_score(&token_info, &creator_history, &fund_flow);
        
        let wallet_age = self.calculate_wallet_age(creator).await?;
        
        Ok(TokenAnalysis {
            token_info,
            creator_history,
            fund_flow,
            risk_score,
            is_new_wallet: wallet_age < 1.0,
            wallet_age,
            social: self.analyze_social_media(&token_info.symbol).await,
            price_change_1h: self.calculate_price_change(token_info.price, token_info.price),
            price_change_24h: self.calculate_price_change(token_info.price, token_info.price),
            volume_24h: 0.0,
            buy_pressure: 0.0,
            sell_pressure: 0.0,
            liquidity_change: 0.0,
            holder_distribution: self.analyze_holder_distribution(mint).await,
            detection_time: chrono::Local::now(),
            first_trade_time: chrono::Local::now(),
            liquidity_add_time: chrono::Local::now(),
            monitor_id: "".to_string(),
            risk_level: "".to_string(),
            next_update_minutes: 0,
            monitoring_status: "".to_string(),
            risk_advice: "".to_string(),
        })
    }

    async fn fetch_token_info(&self, mint: &Pubkey) -> Result<TokenInfo> {
        if let Some(info) = self.cache.lock().await.token_info.get(mint) {
            if info.1.elapsed()? < Duration::from_secs(300) {
                return Ok(info.0.clone());
            }
        }

        let api_key = self.get_next_api_key().await;
        
        let response = self.client
            .get(&format!(
                "https://public-api.birdeye.so/public/token?address={}",
                mint
            ))
            .header("X-API-KEY", api_key)
            .send()
            .await?;
            
        let data: TokenResponse = response.json().await?;
        let info = TokenInfo::from(data);
        
        self.cache.lock().await.token_info.insert(*mint, (info.clone(), SystemTime::now()));
        
        Ok(info)
    }

    async fn analyze_creator_history(&self, creator: &Pubkey) -> Result<CreatorHistory> {
        if let Some(history) = self.cache.lock().await.creator_history.get(creator) {
            if history.1.elapsed()? < Duration::from_secs(1800) {
                return Ok(history.0.clone());
            }
        }

        let api_key = self.get_next_api_key().await;
        
        let response = self.client
            .get(&format!(
                "https://public-api.birdeye.so/public/token_list?creator={}",
                creator
            ))
            .header("X-API-KEY", api_key)
            .send()
            .await?;
            
        let data: TokenListResponse = response.json().await?;
        
        let success_tokens = data.data.items
            .into_iter()
            .filter(|token| token.market_cap >= 10_000_000.0)
            .map(|token| SuccessToken {
                address: token.address,
                symbol: token.symbol,
                name: token.name,
                market_cap: token.market_cap,
                created_at: token.created_at,
            })
            .collect();

        let history = CreatorHistory {
            success_tokens,
            total_tokens: data.data.total,
        };

        self.cache.lock().await.creator_history.insert(*creator, (history.clone(), SystemTime::now()));

        Ok(history)
    }

    async fn trace_fund_flow(&self, address: &Pubkey) -> Result<Vec<FundingChain>> {
        const MAX_DEPTH: u8 = 5;
        let mut visited = HashSet::new();
        self.trace_fund_flow_recursive(address, &mut visited, 0, MAX_DEPTH).await
    }

    async fn trace_fund_flow_recursive(
        &self,
        address: &Pubkey,
        visited: &mut HashSet<Pubkey>,
        depth: u8,
        max_depth: u8,
    ) -> Result<Vec<FundingChain>> {
        if depth >= max_depth || visited.contains(address) {
            return Ok(Vec::new());
        }

        visited.insert(*address);
        let transfers = self.get_address_transfers(address).await?;
        let mut chains = Vec::new();

        for transfer in transfers {
            if transfer.amount < 1.0 {
                continue;
            }

            let source = transfer.source;
            if visited.contains(&source) {
                continue;
            }

            let success_tokens = self.check_address_success_tokens(&source).await?;
            let mut chain = FundingChain {
                transfers: vec![Transfer {
                    source,
                    amount: transfer.amount,
                    timestamp: transfer.timestamp,
                    success_tokens: if success_tokens.is_empty() {
                        None
                    } else {
                        Some(success_tokens)
                    },
                }],
                total_amount: transfer.amount,
                risk_level: 0,
                source_wallet: "".to_string(),
                intermediate_wallet: "".to_string(),
                destination_wallet: "".to_string(),
            };

            let sub_chains = self.trace_fund_flow_recursive(&source, visited, depth + 1, max_depth).await?;
            
            for mut sub_chain in sub_chains {
                sub_chain.transfers.extend(chain.transfers.clone());
                sub_chain.total_amount += chain.total_amount;
                chains.push(sub_chain);
            }

            if chain.transfers.iter().any(|t| t.success_tokens.is_some()) {
                chains.push(chain);
            }
        }

        Ok(chains)
    }

    async fn get_address_transfers(&self, address: &Pubkey) -> Result<Vec<Transfer>> {
        let api_key = self.get_next_api_key().await;
        
        let response = self.client
            .get(&format!(
                "https://public-api.birdeye.so/public/address_activity?address={}",
                address
            ))
            .header("X-API-KEY", api_key)
            .send()
            .await?;
            
        let data: AddressActivityResponse = response.json().await?;
        
        Ok(data.data.items.into_iter()
            .filter(|tx| tx.amount >= 1.0)
            .map(|tx| Transfer {
                source: tx.source,
                amount: tx.amount,
                timestamp: tx.timestamp,
                success_tokens: None,
            })
            .collect())
    }

    async fn check_address_success_tokens(&self, address: &Pubkey) -> Result<Vec<SuccessToken>> {
        let api_key = self.get_next_api_key().await;
        
        let response = self.client
            .get(&format!(
                "https://public-api.birdeye.so/public/token_list?creator={}",
                address
            ))
            .header("X-API-KEY", api_key)
            .send()
            .await?;
            
        let data: TokenListResponse = response.json().await?;
        
        Ok(data.data.items
            .into_iter()
            .filter(|token| token.market_cap >= 10_000_000.0)
            .map(|token| SuccessToken {
                address: token.address,
                symbol: token.symbol,
                name: token.name,
                market_cap: token.market_cap,
                created_at: token.created_at,
            })
            .collect())
    }

    async fn calculate_wallet_age(&self, address: &Pubkey) -> Result<f64> {
        let client = &self.rpc_pool.clients[0];
        
        let signatures = client
            .get_signatures_for_address(address)
            .await?;
            
        if let Some(oldest_tx) = signatures.last() {
            let age = SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)?
                .as_secs() as f64 - oldest_tx.block_time.unwrap_or(0) as f64;
                
            Ok(age / (24.0 * 3600.0))
        } else {
            Ok(0.0)
        }
    }

    fn calculate_risk_score(
        &self,
        token_info: &TokenInfo,
        creator_history: &CreatorHistory,
        fund_flow: &[FundingChain]
    ) -> u8 {
        let mut score = 50;

        if !token_info.verified {
            score += 10;
        }
        if token_info.holder_concentration > 80.0 {
            score += 20;
        }
        if token_info.liquidity < 10.0 {
            score += 15;
        }

        if creator_history.success_tokens.is_empty() {
            score += 20;
        }

        let transit_wallets = fund_flow.iter()
            .flat_map(|chain| &chain.transfers)
            .filter(|t| t.success_tokens.is_none())
            .count();

        if transit_wallets > 2 {
            score += 15;
        }

        score.min(100)
    }

    async fn send_notification(&self, analysis: &TokenAnalysis) -> Result<()> {
        let message = self.format_message(analysis);
        
        for key in &self.config.serverchan.keys {
            if let Err(e) = self.send_server_chan(key, &message, analysis).await {
                log::error!("ServerChan push failed: {}", e);
            }
        }
        
        for group in &self.config.wcf.groups {
            if let Err(e) = self.send_wechat(group, &message).await {
                log::error!("WeChatFerry push failed for {}: {}", group.name, e);
            }
        }
        
        Ok(())
    }

    async fn send_server_chan(&self, key: &str, message: &str, msg_type: &str) -> Result<()> {
        let title = match msg_type {
            "alert" => "âš ï¸ ç³»ç»Ÿå¼‚å¸¸å‘Šè­¦",
            "heartbeat" => "ğŸ’“ ç›‘æ§ç³»ç»Ÿå¿ƒè·³",
            _ => "ğŸ†• æ–°ä»£å¸é¢„è­¦",
        };

        let client = reqwest::Client::builder()
            .timeout(Duration::from_secs(10))
            .build()?;
            
        let res = client
            .post(&format!("https://sctapi.ftqq.com/{}.send", key))
            .form(&[
                ("title", title),
                ("desp", &format!("```\n{}\n```", message)),
            ])
            .send()
            .await?;
            
        if !res.status().is_success() {
            return Err(anyhow!("æ¨é€å¤±è´¥: {}", res.text().await?));
        }
        
        Ok(())
    }

    async fn send_wechat(&self, group: &WeChatGroup, message: &str) -> Result<()> {
        log::info!("Sending WeChat message to {}: {}", group.name, message);
        Ok(())
    }

    fn format_message(&self, analysis: &TokenAnalysis) -> String {
        let data = NotificationData {
            risk_level: self.get_risk_level(analysis.risk_score),
            attention_level: self.get_attention_level(analysis.risk_score),
            symbol: analysis.token_info.symbol.clone(),
            name: analysis.token_info.name.clone(),
            contract: analysis.token_info.mint.to_string(),
            creator: analysis.token_info.creator.to_string(),
            supply: self.format_supply(analysis.token_info.supply),
            initial_price: analysis.token_info.price,
            current_price: analysis.token_info.price,
            market_cap: self.format_market_cap(analysis.token_info.market_cap),
            liquidity: analysis.token_info.liquidity,
            price_change: self.calculate_price_change(
                analysis.token_info.price,
                analysis.token_info.price
            ),
            lock_info: self.format_lock_info(&analysis.token_info),
            holder_count: analysis.token_info.holder_count,
            concentration: analysis.token_info.holder_concentration,
            fund_flow: self.format_fund_flow(&analysis.fund_flow),
            creator_analysis: self.format_creator_analysis(&analysis.creator_history),
            risk_assessment: self.format_risk_assessment(analysis),
            social_market: self.format_social_market(analysis),
            holder_distribution: self.format_holder_distribution(analysis),
            quick_links: self.format_quick_links(&analysis.token_info),
            monitor_info: self.format_monitor_info(analysis),
            risk_tips: self.get_risk_tips(analysis.risk_score),
            main_risks: self.get_main_risks(analysis),
            suggestion: self.get_suggestion(analysis.risk_score),
        };

        self.render_template(NOTIFICATION_TEMPLATE, &data)
    }

    fn render_template(&self, template: &str, data: &NotificationData) -> String {
        template
            .replace("{risk_level}", &data.risk_level)
            .replace("{attention_level}", &data.attention_level)
            .replace("{symbol}", &data.symbol)
            .replace("{name}", &data.name)
            .replace("{contract}", &data.contract)
            .replace("{creator}", &data.creator)
            .replace("{supply}", &data.supply)
            .replace("{initial_price}", &format!("{:.8}", data.initial_price))
            .replace("{current_price}", &format!("{:.8}", data.current_price))
            .replace("{market_cap}", &data.market_cap)
            .replace("{liquidity}", &format!("{:.1}", data.liquidity))
            .replace("{price_change}", &format!("{:.1}", data.price_change))
            .replace("{lock_info}", &data.lock_info)
            .replace("{holder_count}", &data.holder_count.to_string())
            .replace("{concentration}", &format!("{:.1}", data.concentration))
            .replace("{fund_flow}", &data.fund_flow)
            .replace("{creator_analysis}", &data.creator_analysis)
            .replace("{risk_assessment}", &data.risk_assessment)
            .replace("{social_market}", &data.social_market)
            .replace("{holder_distribution}", &data.holder_distribution)
            .replace("{quick_links}", &data.quick_links)
            .replace("{monitor_info}", &data.monitor_info)
            .replace("{risk_tips}", &data.risk_tips)
            .replace("{main_risks}", &data.main_risks)
            .replace("{suggestion}", &data.suggestion)
    }

    fn get_risk_level(&self, risk_score: u8) -> String {
        match risk_score {
            0..=39 => "ä½é£é™©".to_string(),
            40..=69 => "ä¸­é£é™©".to_string(),
            70..=100 => "é«˜é£é™©".to_string(),
            _ => "æœªçŸ¥".to_string(),
        }
    }

    fn get_attention_level(&self, risk_score: u8) -> String {
        match risk_score {
            0..=39 => "æ— å…³æ³¨".to_string(),
            40..=69 => "å…³æ³¨".to_string(),
            70..=100 => "é«˜åº¦å…³æ³¨".to_string(),
            _ => "æœªçŸ¥".to_string(),
        }
    }

    fn format_supply(&self, supply: u64) -> String {
        format!("{}", supply)
    }

    fn format_market_cap(&self, market_cap: f64) -> String {
        format!("${:.2}M", market_cap / 1_000_000.0)
    }

    fn format_lock_info(&self, token_info: &TokenInfo) -> String {
        format!("é”ä»“: {}% (180å¤©)", (token_info.liquidity / 100.0 * 180.0) as u64)
    }

    fn format_creator_analysis(&self, history: &CreatorHistory) -> String {
        let active_tokens = history.success_tokens.len();
        let success_rate = active_tokens as f64 / history.total_tokens as f64;
        
        let best_token = history.success_tokens.iter()
            .max_by_key(|t| (t.market_cap * 1000.0) as u64)
            .unwrap();
        let avg_market_cap = history.success_tokens.iter()
            .map(|t| t.market_cap)
            .sum::<f64>() / active_tokens as f64;
        let latest_token = history.success_tokens.iter()
            .max_by_key(|t| t.created_at)
            .unwrap();
        
        format!(
            "å†å²ä»£å¸: {}ä¸ª | æˆåŠŸé¡¹ç›®: {}ä¸ª | æˆåŠŸç‡: {:.1}%\n\
            æœ€ä½³ä¸šç»©: {}(${:.1}M) | å¹³å‡å¸‚å€¼: ${:.1}M | æœ€è¿‘: {}(${:.1}M)\n",
            history.total_tokens,
            active_tokens,
            success_rate * 100.0,
            best_token.symbol,
            best_token.market_cap / 1_000_000.0,
            avg_market_cap / 1_000_000.0,
            latest_token.symbol,
            latest_token.market_cap / 1_000_000.0
        )
    }

    fn format_risk_assessment(&self, analysis: &TokenAnalysis) -> String {
        format!(
            "é£é™©è¯„åˆ†: {} | é£é™©ç­‰çº§: {}\n\
            ç§¯æå› ç´ :\n\
            1. åˆ›å»ºè€…æœ‰æˆåŠŸé¡¹ç›®ç»éªŒ\n\
            2. èµ„é‡‘æ¥æºæ¸…æ™°å¯è¿½æº¯\n\
            3. ä»£ç å·²éªŒè¯\n\
            é£é™©å› ç´ :\n\
            1. æŒå¸ç›¸å¯¹é›†ä¸­ ({:.1}%)\n\
            2. éƒ¨åˆ†èµ„é‡‘æ¥è‡ªæ–°é’±åŒ…\n",
            analysis.risk_score,
            if analysis.risk_score >= 70 { "é«˜" }
            else if analysis.risk_score >= 40 { "ä¸­" }
            else { "ä½" },
            analysis.token_info.holder_concentration
        )
    }

    fn format_social_market(&self, analysis: &TokenAnalysis) -> String {
        format!(
r#"ğŸ“± ç¤¾äº¤åª’ä½“ & å¸‚åœºè¡¨ç°
â”£â” ç¤¾äº¤æ•°æ®: Twitter({:,},{}%) | Discord({:,},{}%æ´»è·ƒ) | TG({:,})
â”£â” ä»·æ ¼å˜åŠ¨: 1h({}%) | 24h({}%) | é¦–æ¬¡äº¤æ˜“({}%)
â”—â” äº¤æ˜“æ•°æ®: 24hé‡({}) | ä¹°å‹({}%) | å–å‹({}%) | æµåŠ¨æ€§å˜åŒ–({}%)"#,
            analysis.social.twitter_followers,
            format_change(analysis.social.twitter_growth),
            analysis.social.discord_members,
            analysis.social.discord_activity,
            analysis.social.telegram_members,
            format_change(analysis.price_change_1h),
            format_change(analysis.price_change_24h),
            format_change(analysis.price_change_initial),
            format_volume(analysis.volume_24h),
            analysis.buy_pressure,
            analysis.sell_pressure,
            format_change(analysis.liquidity_change)
        )
    }

    fn format_holder_distribution(&self, analysis: &TokenAnalysis) -> String {
        format!(
r#"ğŸ‘¥ æŒå¸åˆ†å¸ƒ
â”£â” é›†ä¸­åº¦: Top10({}%) | Top50({}%) | Top100({}%)
â”£â” åœ°å€åˆ†ç±»: æ•£æˆ·{}ä¸ª({}%) | ä¸­æˆ·{}ä¸ª({}%) | å¤§æˆ·{}ä¸ª({}%)
â”—â” é‡è¦åœ°å€: {}ä¸ªäº¤æ˜“æ‰€ | {}ä¸ªå¤§æˆ· | {}ä¸ªåšå¸‚å•†"#,
            analysis.holder_distribution.top_10_percentage,
            analysis.holder_distribution.top_50_percentage,
            analysis.holder_distribution.top_100_percentage,
            analysis.holder_distribution.holder_categories[0].count,
            analysis.holder_distribution.holder_categories[0].percentage,
            analysis.holder_distribution.holder_categories[1].count,
            analysis.holder_distribution.holder_categories[1].percentage,
            analysis.holder_distribution.holder_categories[2].count,
            analysis.holder_distribution.holder_categories[2].percentage,
            analysis.holder_distribution.exchange_count,
            analysis.holder_distribution.whale_count,
            analysis.holder_distribution.market_maker_count
        )
    }

    fn format_quick_links(&self, token_info: &TokenInfo) -> String {
        let short_addr = self.format_short_address(&token_info.mint);
        let short_creator = self.format_short_address(&token_info.creator);
        
        format!(
r#"ğŸ”— å¿«é€Ÿé“¾æ¥ (ç‚¹å‡»å¤åˆ¶)
â”£â” Birdeye: birdeye.so/token/{} ğŸ“‹
â”£â” Solscan: solscan.io/token/{} ğŸ“‹
â”—â” åˆ›å»ºè€…: solscan.io/account/{} ğŸ“‹"#,
            short_addr,
            short_addr,
            short_creator
        )
    }

    fn format_monitor_info(&self, analysis: &TokenAnalysis) -> String {
        format!(
            "ç›‘æ§ä¿¡æ¯:\n\
            å‘ç°æ—¶é—´: {} (UTC+8)\n\
            é¦–æ¬¡äº¤æ˜“: {} (UTC+8)\n\
            åˆå§‹ä»·æ ¼: ${:.8}\n\
            å½“å‰æ¶¨å¹…: {:.1}%\n",
            chrono::Local::now().format("%Y-%m-%d %H:%M:%S"),
            self.get_first_trade_time(analysis.token_info),
            analysis.token_info.price,
            self.calculate_price_change(analysis.token_info)
        )
    }

    fn get_risk_tips(&self, risk_score: u8) -> String {
        match risk_score {
            0..=39 => "æ— é£é™©æç¤º".to_string(),
            40..=69 => "æ³¨æ„é£é™©".to_string(),
            70..=100 => "é«˜åº¦é£é™©æç¤º".to_string(),
            _ => "æœªçŸ¥é£é™©æç¤º".to_string(),
        }
    }

    fn get_main_risks(&self, analysis: &TokenAnalysis) -> String {
        format!(
            "ä¸»è¦é£é™©:\n\
            1. æŒå¸ç›¸å¯¹é›†ä¸­ ({:.1}%)\n\
            2. éƒ¨åˆ†èµ„é‡‘æ¥è‡ªæ–°é’±åŒ…\n\
            3. ä»£ç å·²éªŒè¯\n\
            4. åˆ›å»ºè€…å†å²è‰¯å¥½\n\
            5. æµåŠ¨æ€§å……è¶³\n\
            6. èµ„é‡‘æ¥æºæ¸…æ™°å¯è¿½æº¯\n\
            7. å¸‚åœºåˆ†æ\n\
            8. ç¤¾äº¤åª’ä½“\n\
            9. ä»£ç æ›´æ–°\n\
            10. å…¶ä»–é£é™©å› ç´ \n",
            analysis.token_info.holder_concentration
        )
    }

    fn get_suggestion(&self, risk_score: u8) -> String {
        match risk_score {
            0..=39 => "æ— å»ºè®®".to_string(),
            40..=69 => "å…³æ³¨å¸‚åœºåŠ¨æ€".to_string(),
            70..=100 => "é«˜åº¦å…³æ³¨å¸‚åœºåŠ¨æ€".to_string(),
            _ => "æœªçŸ¥å»ºè®®".to_string(),
        }
    }

    fn calculate_price_change(&self, initial_price: f64, current_price: f64) -> f64 {
        ((current_price - initial_price) / initial_price) * 100.0
    }

    fn get_initial_price(&self, token_info: &TokenInfo) -> Option<f64> {
        Some(0.00000085) // ç¤ºä¾‹å€¼ï¼Œå®é™…åº”ä»APIè·å–
    }

    fn get_first_trade_time(&self, token_info: &TokenInfo) -> String {
        chrono::Local::now()
            .checked_add_signed(chrono::Duration::minutes(5))
            .unwrap()
            .format("%Y-%m-%d %H:%M:%S")
            .to_string()
    }

    async fn analyze_social_media(&self, token_symbol: &str) -> SocialMediaStats {
        SocialMediaStats {
            twitter_followers: 25800,
            twitter_growth_rate: 1.2,
            twitter_authenticity: 85.0,
            discord_members: 15200,
            discord_activity: 75.0,
            discord_messages_24h: 2500,
            telegram_members: 12500,
            telegram_online_rate: 35.0,
            website_age_days: 15,
        }
    }

    async fn analyze_contract(&self, mint: &Pubkey) -> ContractAnalysis {
        ContractAnalysis {
            is_upgradeable: false,
            has_mint_authority: false,
            has_freeze_authority: false,
            has_blacklist: false,
            locked_liquidity: true,
            max_tx_amount: Some(1_000_000.0),
            buy_tax: 3.0,
            sell_tax: 3.0,
        }
    }

    fn calculate_comprehensive_score(&self, analysis: &TokenAnalysis) -> ComprehensiveScore {
        ComprehensiveScore {
            total_score: 35,
            liquidity_score: 80,
            contract_score: 90,
            team_score: 75,
            social_score: 65,
            risk_factors: vec![
                "æŒå¸é›†ä¸­åº¦è¾ƒé«˜".to_string(),
                "éƒ¨åˆ†èµ„é‡‘æ¥æºä¸æ˜".to_string(),
            ],
            positive_factors: vec![
                "ä»£ç å·²éªŒè¯".to_string(),
                "åˆ›å»ºè€…å†å²è‰¯å¥½".to_string(),
                "æµåŠ¨æ€§å……è¶³".to_string(),
            ],
        }
    }

    async fn analyze_price_trend(&self, mint: &Pubkey) -> PriceTrendAnalysis {
        PriceTrendAnalysis {
            price_change_1h: 25.5,
            price_change_24h: 125.0,
            volume_change_24h: 250.0,
            liquidity_change_24h: 180.0,
            buy_pressure: 65.0,
            sell_pressure: 35.0,
            major_transactions: vec![
                Transaction {
                    amount: 500.0,
                    price: 0.00000145,
                    timestamp: SystemTime::now(),
                    transaction_type: TransactionType::Buy,
                },
                // ... å…¶ä»–é‡è¦äº¤æ˜“
            ],
        }
    }

    async fn analyze_holder_distribution(&self, mint: &Pubkey) -> HolderDistribution {
        HolderDistribution {
            top_10_percentage: 35.8,
            top_50_percentage: 65.2,
            top_100_percentage: 80.5,
            average_balance: 15000.0,
            median_balance: 5000.0,
            gini_coefficient: 0.45,
            holder_categories: vec![
                HolderCategory {
                    category: "æ•£æˆ·".to_string(),
                    percentage: 45.0,
                    count: 1000,
                },
                HolderCategory {
                    category: "ä¸­æˆ·".to_string(),
                    percentage: 35.0,
                    count: 200,
                },
                HolderCategory {
                    category: "å¤§æˆ·".to_string(),
                    percentage: 20.0,
                    count: 58,
                },
            ],
        }
    }

    fn test_monitor_output(&self) {
        println!("\n{}", ">>> æ¨¡æ‹Ÿç›‘æ§è¾“å‡º...".yellow());
        
        let mock_analysis = TokenAnalysis {
            token_info: TokenInfo {
                mint: "DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263".parse().unwrap(),
                name: "PEPE2".to_string(),
                symbol: "PEPE2".to_string(),
                market_cap: 15_000_000.0,
                liquidity: 2_500.0,
                holder_count: 1258,
                holder_concentration: 35.8,
                verified: true,
                price: 0.00000145,
                supply: 420_690_000_000_000,
                creator: "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU".parse().unwrap(),
            },
            creator_history: CreatorHistory {
                success_tokens: vec![
                    SuccessToken {
                        address: "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU".parse().unwrap(),
                        symbol: "SAMO".to_string(),
                        name: "Samoyedcoin".to_string(),
                        market_cap: 25_000_000.0,
                        created_at: 1640995200,
                    },
                    SuccessToken {
                        address: "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v".parse().unwrap(),
                        symbol: "USDC".to_string(),
                        name: "USD Coin".to_string(),
                        market_cap: 1_200_000_000.0,
                        created_at: 1620000000,
                    },
                ],
                total_tokens: 5,
            },
            fund_flow: vec![
                FundingChain {
                    transfers: vec![
                        Transfer {
                            source: "DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263".parse().unwrap(),
                            amount: 1250.5,
                            timestamp: 1711008000, // 2024-03-21 12:00:00
                            success_tokens: Some(vec![
                                SuccessToken {
                                    address: "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU".parse().unwrap(),
                                    symbol: "SAMO".to_string(),
                                    name: "Samoyedcoin".to_string(),
                                    market_cap: 25_000_000.0,
                                    created_at: 1640995200,
                                }
                            ]),
                        }
                    ],
                    total_amount: 1250.5,
                }
            ],
            risk_score: 35,
            is_new_wallet: false,
            wallet_age: 245.5,
            social: self.analyze_social_media(&"PEPE2".to_string()).await,
            price_change_1h: 0.0,
            price_change_24h: 0.0,
            volume_24h: 0.0,
            buy_pressure: 0.0,
            sell_pressure: 0.0,
            liquidity_change: 0.0,
            holder_distribution: self.analyze_holder_distribution(mint).await,
            detection_time: chrono::Local::now(),
            first_trade_time: chrono::Local::now(),
            liquidity_add_time: chrono::Local::now(),
            monitor_id: "".to_string(),
            risk_level: "".to_string(),
            next_update_minutes: 0,
            monitoring_status: "".to_string(),
            risk_advice: "".to_string(),
        };

        let output = format!(
            ">>> å‘ç°æ–°ä»£å¸ - é«˜åº¦å…³æ³¨! ğŸš¨\n\
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ”” æ–°ä»£å¸åˆ†ææŠ¥å‘Š (UTC+8) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n\n\
            ğŸ“‹ åˆçº¦ä¿¡æ¯\n\
            â”£â” ä»£å¸: PEPE2 (Pepe Solana)\n\
            â”£â” åˆçº¦åœ°å€: DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263 ğŸ“‹\n\
            â”—â” åˆ›å»ºè€…é’±åŒ…: 7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU ğŸ“‹\n\n\
            ğŸ“Š ä»£å¸æ•°æ®\n\
            â”£â” å‘è¡Œé‡: 420.69T | æŒæœ‰äºº: 1,258 | éªŒè¯çŠ¶æ€: âœ“\n\
            â”£â” å½“å‰ä»·æ ¼: $0.00000145 (+125%) | å¸‚å€¼: $15M\n\
            â”—â” æµåŠ¨æ€§: 2,500 SOL | æŒå¸é›†ä¸­åº¦: 35.8% | é”ä»“: 20%(180å¤©)\n\n\
            ğŸ’¸ èµ„é‡‘è¿½æº¯ (åˆ›å»ºè€…é’±åŒ…æ€»æ”¶æ¬¾: 5,250.50 SOL)\n\
            â”£â” èµ„é‡‘æ¥æº#1 (2,000.50 SOL) - å·²éªŒè¯èµ„é‡‘é“¾\n\
            â”ƒ   åˆ›å»ºè€…é’±åŒ… [2024-03-21 12:00] 7xKX...gAsU\n\
            â”ƒ   â†‘ 2000.50 SOL â”” ä¸­è½¬é’±åŒ…A [2024-03-20 15:30] DezX...B263 (SAMOåˆ›å»ºè€…)\n\
            â”ƒ   â†‘ 2000.50 SOL â”” ä¸­è½¬é’±åŒ…B [2024-03-19 09:15] EPjF...Dt1v (BONKæ—©æœŸæŠ•èµ„è€…)\n\
            â”ƒ   â†‘ 2000.50 SOL â”” æºå¤´é’±åŒ…C [2024-03-18 10:00] ORCA...Zt1v (å·²éªŒè¯äº¤æ˜“æ‰€)\n\n\
            ğŸ“Š åˆ›å»ºè€…å†å²åˆ†æ\n\
            â”£â” å†å²é¡¹ç›®æ•°: 5ä¸ª | æˆåŠŸé¡¹ç›®: 2ä¸ª | æˆåŠŸç‡: 40.0%\n\
            â”£â” ä»£å¸åˆ—è¡¨:\n\
            â”ƒ   â”£â” 1. SAMO: å¸‚å€¼ $25.0M (2023-12) - æœ€ä½³ä¸šç»©\n\
            â”ƒ   â”£â” 2. BONK: å¸‚å€¼ $12.0M (2024-01)\n\
            â”ƒ   â”—â” 3. PEPE2: å¸‚å€¼ $15.0M (å½“å‰é¡¹ç›®)\n\
            â”—â” å¹³å‡å¸‚å€¼: $17.33M\n\n\
            ğŸ¯ ç»¼åˆé£é™©è¯„ä¼°\n\
            â”£â” æ€»ä½“è¯„åˆ†: 35/100 (ä½é£é™©)\n\
            â”£â” ç§¯æå› ç´ :\n\
            â”ƒ   â”£â” 1. åˆ›å»ºè€…æœ‰æˆåŠŸé¡¹ç›®ç»éªŒ\n\
            â”ƒ   â”£â” 2. èµ„é‡‘æ¥æºæ¸…æ™°å¯è¿½æº¯\n\
            â”ƒ   â”—â” 3. ä»£ç å·²éªŒè¯\n\
            â”—â” é£é™©å› ç´ :\n\
                â”£â” 1. æŒå¸ç›¸å¯¹é›†ä¸­ (35.8%)\n\
                â”—â” 2. éƒ¨åˆ†èµ„é‡‘æ¥è‡ªæ–°é’±åŒ…\n\n\
            ğŸ”— å¿«é€Ÿé“¾æ¥\n\
            â”£â” Birdeye: https://birdeye.so/token/DezXAZ...B263 ğŸ“‹\n\
            â”£â” Solscan: https://solscan.io/token/DezXAZ...B263 ğŸ“‹\n\
            â”—â” åˆ›å»ºè€…: https://solscan.io/account/7xKXt...gAsU ğŸ“‹\n\n\
            â° ç›‘æ§ä¿¡æ¯\n\
            â”£â” å‘ç°æ—¶é—´: 2024-03-21 12:00:00 (UTC+8)\n\
            â”£â” é¦–æ¬¡äº¤æ˜“: 2024-03-21 12:05:30 (UTC+8)\n\
            â”£â” åˆå§‹ä»·æ ¼: $0.00000085\n\
            â”—â” å½“å‰æ¶¨å¹…: +70.5%\n"
        );

        println!("{}", output);
    }

    fn get_wallet_role(&self, address: &Pubkey) -> String {
        if self.is_exchange_wallet(address) {
            "äº¤æ˜“æ‰€é’±åŒ…".to_string()
        } else if self.is_contract_wallet(address) {
            "åˆçº¦é’±åŒ…".to_string()
        } else {
            "æ™®é€šé’±åŒ…".to_string()
        }
    }

    fn get_wallet_description(&self, transfer: &Transfer) -> String {
        if let Some(ref tokens) = transfer.success_tokens {
            if !tokens.is_empty() {
                format!("{} åˆ›å»ºè€…", tokens[0].symbol)
            } else {
                "ä¸­è½¬é’±åŒ…".to_string()
            }
        } else {
            "æ–°é’±åŒ…".to_string()
        }
    }

    fn is_exchange_wallet(&self, address: &Pubkey) -> bool {
        // å®ç°äº¤æ˜“æ‰€é’±åŒ…æ£€æµ‹é€»è¾‘
        false // ä¸´æ—¶è¿”å›
    }

    fn is_contract_wallet(&self, address: &Pubkey) -> bool {
        // å®ç°åˆçº¦é’±åŒ…æ£€æµ‹é€»è¾‘
        false // ä¸´æ—¶è¿”å›
    }

    async fn warm_up_cache(&self) -> Result<()> {
        // é¢„åŠ è½½å¸¸ç”¨æ•°æ®
        Ok(())
    }

    async fn process_blocks_batch(&self, slots: Vec<u64>) -> Result<()> {
        let futures: Vec<_> = slots.into_iter()
            .map(|slot| self.process_block(slot, &self.token_tx))
            .collect();
            
        join_all(futures).await
            .into_iter()
            .collect::<Result<Vec<_>>>()?;
        Ok(())
    }

    // åœ¨ TokenMonitor ç»“æ„ä½“å®šä¹‰ä¹‹å‰
    #[derive(Debug, Clone)]
    pub struct ServiceState {
        running: Arc<AtomicBool>,
        last_error: Arc<Mutex<Option<String>>>,
        start_time: SystemTime,
        processed_blocks: Arc<AtomicUsize>,
        processed_tokens: Arc<AtomicUsize>,
    }

    impl ServiceState {
        fn new() -> Self {
            Self {
                running: Arc::new(AtomicBool::new(false)),
                last_error: Arc::new(Mutex::new(None)),
                start_time: SystemTime::now(),
                processed_blocks: Arc::new(AtomicUsize::new(0)),
                processed_tokens: Arc::new(AtomicUsize::new(0)),
            }
        }
    }

    pub async fn start_service(&self) -> Result<()> {
        log::info!("å¯åŠ¨ç›‘æ§æœåŠ¡...");
        self.service_state.running.store(true, Ordering::SeqCst);
        
        // é¢„çƒ­ç¼“å­˜
        self.warm_up_cache().await?;
        
        // å¯åŠ¨å·¥ä½œçº¿ç¨‹
        let (block_tx, block_rx) = mpsc::channel(1000);
        let (token_tx, token_rx) = mpsc::channel(1000);
        
        // å¯åŠ¨åŒºå—å¤„ç†
        self.start_worker_threads(block_rx, token_tx.clone()).await?;
        
        // å¯åŠ¨ä»£å¸åˆ†æ
        self.start_token_analysis(token_rx).await?;
        
        // å¯åŠ¨æŒ‡æ ‡æ”¶é›†
        self.start_metrics_collection().await?;
        
        // å¯åŠ¨å¿ƒè·³æ¨é€
        self.start_heartbeat();
        
        // å¯åŠ¨ä»£ç†ç»´æŠ¤ä»»åŠ¡
        let proxy_pool = self.proxy_pool.clone();
        tokio::spawn(async move {
            let mut interval = time::interval(Duration::from_secs(300));
            loop {
                interval.tick().await;
                proxy_pool.lock().await.maintain().await;
            }
        });
        
        Ok(())
    }

    pub async fn stop_service(&self) -> Result<()> {
        log::info!("åœæ­¢ç›‘æ§æœåŠ¡...");
        self.service_state.running.store(false, Ordering::SeqCst);
        Ok(())
    }

    pub async fn health_check(&self) -> Result<ServiceHealth> {
        let uptime = SystemTime::now()
            .duration_since(self.service_state.start_time)?;
            
        Ok(ServiceHealth {
            running: self.service_state.running.load(Ordering::SeqCst),
            uptime: uptime.as_secs(),
            processed_blocks: self.service_state.processed_blocks.load(Ordering::SeqCst),
            processed_tokens: self.service_state.processed_tokens.load(Ordering::SeqCst),
            last_error: self.service_state.last_error.lock().await.clone(),
        })
    }

    async fn start_metrics_collection(&self) -> Result<()> {
        let metrics = self.metrics.clone();
        let service_state = self.service_state.clone();
        
        tokio::spawn(async move {
            while service_state.running.load(Ordering::SeqCst) {
                // æ”¶é›†å¹¶è®°å½•æŒ‡æ ‡
                let health = self.health_check().await?;
                log::info!("æœåŠ¡çŠ¶æ€: {:?}", health);
                
                tokio::time::sleep(Duration::from_secs(60)).await;
            }
            Ok::<(), anyhow::Error>(())
        });
        
        Ok(())
    }

    async fn analyze_token_metrics(&self, mint: &Pubkey) -> Result<TokenMetrics> {
        let token_info = self.fetch_token_info(mint).await?;
        
        // è®¡ç®—åŸºç¡€æŒ‡æ ‡
        let supply_score = self.calculate_supply_score(token_info.supply);
        let liquidity_score = self.calculate_liquidity_score(token_info.liquidity);
        let holder_score = self.calculate_holder_score(
            token_info.holder_count,
            token_info.holder_concentration
        );
        
        // è®¡ç®—ç»¼åˆé£é™©åˆ†æ•°
        let risk_score = (supply_score + liquidity_score + holder_score) / 3.0;
        
        Ok(TokenMetrics {
            supply_score,
            liquidity_score, 
            holder_score,
            risk_score,
            market_cap: token_info.market_cap,
            price: token_info.price,
            verified: token_info.verified,
        })
    }

    fn calculate_supply_score(&self, supply: u64) -> f64 {
        // ä¾›åº”é‡è¯„åˆ†ç®—æ³•
        let base_score = if supply < 1_000_000 {
            100.0
        } else if supply < 1_000_000_000 {
            75.0
        } else if supply < 1_000_000_000_000 {
            50.0
        } else {
            25.0
        };

        // åº”ç”¨ä¿®æ­£å› å­
        let correction = (supply as f64).log10() * 5.0;
        (base_score - correction).max(0.0).min(100.0)
    }

    fn calculate_liquidity_score(&self, liquidity: f64) -> f64 {
        // æµåŠ¨æ€§è¯„åˆ†ç®—æ³•
        let base_score = if liquidity < 1000.0 {
            25.0
        } else if liquidity < 10_000.0 {
            50.0
        } else if liquidity < 100_000.0 {
            75.0
        } else {
            100.0
        };

        // åº”ç”¨ä¿®æ­£å› å­
        let correction = liquidity.log10() * 10.0;
        (base_score + correction).max(0.0).min(100.0)
    }

    fn calculate_holder_score(&self, holder_count: u64, concentration: f64) -> f64 {
        // æŒæœ‰è€…è¯„åˆ†ç®—æ³•
        let count_score = if holder_count < 100 {
            25.0
        } else if holder_count < 1000 {
            50.0
        } else if holder_count < 10000 {
            75.0
        } else {
            100.0
        };

        // è€ƒè™‘æŒä»“é›†ä¸­åº¦
        let concentration_penalty = concentration * 50.0;
        (count_score - concentration_penalty).max(0.0)
    }

    async fn trace_fund_flow(&self, address: &Pubkey) -> Result<Vec<FundingChain>> {
        let mut chains = Vec::new();
        let mut visited = HashSet::new();
        
        // è·å–åœ°å€æ´»åŠ¨å†å²
        let activities = self.fetch_address_activities(address).await?;
        
        for activity in activities {
            if visited.contains(&activity.signature) {
                continue;
            }
            
            let mut chain = FundingChain {
                transfers: vec![Transfer {
                    source: activity.source,
                    amount: activity.amount,
                    timestamp: activity.timestamp,
                    success_tokens: None,
                }],
                total_amount: activity.amount,
                risk_level: 0,
                source_wallet: "".to_string(),
                intermediate_wallet: "".to_string(),
                destination_wallet: "".to_string(),
            };
            
            // é€’å½’è¿½è¸ªèµ„é‡‘æµå‘
            self.trace_chain(&mut chain, &activity.source, &mut visited).await?;
            
            if !chain.transfers.is_empty() {
                chains.push(chain);
            }
        }
        
        Ok(chains)
    }

    async fn trace_chain(
        &self,
        chain: &mut FundingChain,
        current: &Pubkey,
        visited: &mut HashSet<String>,
    ) -> Result<()> {
        const MAX_DEPTH: usize = 5;
        
        if chain.transfers.len() >= MAX_DEPTH {
            return Ok(());
        }
        
        let activities = self.fetch_address_activities(current).await?;
        
        for activity in activities {
            if visited.contains(&activity.signature) {
                continue;
            }
            
            visited.insert(activity.signature.clone());
            
            // è·å–æˆåŠŸåˆ›å»ºçš„ä»£å¸
            let success_tokens = self.get_success_tokens(current).await?;
            
            chain.transfers.push(Transfer {
                source: activity.source,
                amount: activity.amount,
                timestamp: activity.timestamp,
                success_tokens: Some(success_tokens),
            });
            
            chain.total_amount += activity.amount;
            
            // é€’å½’è¿½è¸ª
            self.trace_chain(chain, &activity.source, visited).await?;
        }
        
        Ok(())
    }

    async fn save_monitor_state(&self) -> Result<()> {
        let state_file = dirs::home_dir()?
            .join(".solana_pump/state.json");
            
        let state = self.monitor_state.lock().await;
        let content = serde_json::to_string_pretty(&*state)?;
        fs::write(state_file, content)?;
        
        Ok(())
    }

    async fn load_monitor_state() -> Result<MonitorState> {
        let state_file = dirs::home_dir()?
            .join(".solana_pump/state.json");

        if !state_file.exists() {
            return Ok(MonitorState::default());
        }

        let content = fs::read_to_string(state_file)?;
        Ok(serde_json::from_str(&content)?)
    }

    async fn update_metrics(&self) {
        let mut state = self.monitor_state.lock().await;
        let sys = System::new_all();
        
        state.metrics.uptime = SystemTime::now()
            .duration_since(self.service_state.start_time)
            .unwrap_or(Duration::from_secs(0));
            
        state.metrics.cpu_usage = sys.global_cpu_info().cpu_usage();
        state.metrics.memory_usage = sys.used_memory() as f64 / sys.total_memory() as f64 * 100.0;
    }

    async fn auto_recover(&self) -> Result<()> {
        let recovery = Arc::new(Recovery::new());
        
        tokio::spawn(async move {
            loop {
                if let Err(e) = self.check_and_recover().await {
                    log::error!("Recovery failed: {}", e);
                }
                tokio::time::sleep(Duration::from_secs(60)).await;
            }
        });

        Ok(())
    }

    async fn check_and_recover(&self) -> Result<()> {
        // æ£€æŸ¥RPCèŠ‚ç‚¹å¥åº·
        for client in &self.rpc_pool.clients {
            if let Err(e) = client.get_slot().await {
                log::warn!("RPC node {} failed: {}", client.url(), e);
                self.rpc_pool.health_status.insert(client.url(), false);
                self.try_recover_rpc(client).await?;
            }
        }

        // æ£€æŸ¥ç¼“å­˜çŠ¶æ€
        let cache = self.cache.lock().await;
        if cache.blocks.len() > 10000 {
            log::warn!("Cache size too large, cleaning up...");
            self.cleanup_cache().await?;
        }

        // æ£€æŸ¥å¤„ç†å»¶è¿Ÿ
        let metrics = self.metrics.lock().await;
        if metrics.processing_delays.iter().any(|d| d > &Duration::from_secs(5)) {
            log::warn!("Processing delays too high, adjusting batch size...");
            self.batcher.adjust_batch_size();
        }

        Ok(())
    }

    async fn try_recover_rpc(&self, client: &RpcClient) -> Result<()> {
        for _ in 0..3 {
            if client.get_slot().await.is_ok() {
                self.rpc_pool.health_status.insert(client.url(), true);
                return Ok(());
            }
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
        Ok(())
    }

    async fn generate_report(&self) -> Result<String> {
        let mut report = String::new();
        
        // æ·»åŠ æ ‡é¢˜
        report.push_str(&format!(
            "Solana Pump Monitor ç›‘æ§æŠ¥å‘Š\næ—¥æœŸ: {}\n\n",
            chrono::Local::now().format("%Y-%m-%d %H:%M:%S")
        ));

        // æ·»åŠ ç³»ç»ŸçŠ¶æ€
        let metrics = self.metrics.lock().await;
        report.push_str(&format!(
            "ç³»ç»ŸçŠ¶æ€:\n\
            å¤„ç†åŒºå—æ•°: {}\n\
            å¤„ç†äº¤æ˜“æ•°: {}\n\
            ä¸¢å¤±åŒºå—æ•°: {}\n\
            å¹³å‡å¤„ç†å»¶è¿Ÿ: {:.2}ms\n\n",
            metrics.processed_blocks,
            metrics.processed_txs,
            metrics.missed_blocks.len(),
            metrics.processing_delays.iter()
                .map(|d| d.as_millis() as f64)
                .sum::<f64>() / metrics.processing_delays.len() as f64
        ));

        // æ·»åŠ RPCèŠ‚ç‚¹çŠ¶æ€
        report.push_str("RPCèŠ‚ç‚¹çŠ¶æ€:\n");
        for client in &self.rpc_pool.clients {
            let health = self.rpc_pool.health_status.get(&client.url())
                .map_or(false, |v| *v);
            report.push_str(&format!(
                "{}: {}\n",
                client.url(),
                if health { "âœ… æ­£å¸¸" } else { "âŒ å¼‚å¸¸" }
            ));
        }

        // æ·»åŠ å‘Šè­¦ç»Ÿè®¡
        let alerts = self.get_recent_alerts().await?;
        report.push_str(&format!(
            "\nå‘Šè­¦ç»Ÿè®¡:\n\
            é«˜é£é™©: {}\n\
            ä¸­é£é™©: {}\n\
            ä½é£é™©: {}\n",
            alerts.iter().filter(|a| matches!(a.level, AlertLevel::High)).count(),
            alerts.iter().filter(|a| matches!(a.level, AlertLevel::Medium)).count(),
            alerts.iter().filter(|a| matches!(a.level, AlertLevel::Low)).count()
        ));

        Ok(report)
    }

    // è¾…åŠ©æ ¼å¼åŒ–å‡½æ•°
    fn format_change(&self, value: f64) -> String {
        if value > 0.0 {
            format!("+{:.1}%", value)
        } else {
            format!("{:.1}%", value)
        }
    }

    fn format_volume(&self, volume: f64) -> String {
        if volume >= 1_000_000.0 {
            format!("${:.1}M", volume / 1_000_000.0)
        } else if volume >= 1_000.0 {
            format!("${:.1}K", volume / 1_000.0)
        } else {
            format!("${:.1}", volume)
        }
    }

    fn format_short_address(&self, address: &Pubkey) -> String {
        let addr_str = address.to_string();
        format!("{}...{}", 
            &addr_str[..4], 
            &addr_str[addr_str.len()-4..])
    }

    async fn send_alert(&self, title: &str, content: &str) {
        let mut last_alert = self.last_alert.lock().await;
        if last_alert.elapsed().unwrap().as_secs() < 300 { // 5åˆ†é’Ÿé—´éš”
            return;
        }
        
        for key in &self.config.serverchan.keys {
            let message = format!("ğŸš¨ {} ğŸš¨\n\n{}", title, content);
            if let Err(e) = self.send_server_chan(key, &message, "alert").await {
                log::error!("å‘Šè­¦æ¨é€å¤±è´¥: {}", e);
            }
        }
        *last_alert = SystemTime::now();
    }

    async fn start_heartbeat(&self) {
        let interval = Duration::from_secs(self.config.serverchan.heartbeat_interval);
        let mut interval = time::interval(interval);
        loop {
            interval.tick().await;
            self.send_heartbeat().await;
        }
    }

    async fn send_heartbeat(&self) {
        let state = self.monitor_state.lock().await;
        let metrics = self.metrics.lock().await;
        
        let message = format!(
            "ğŸ’“ ç³»ç»Ÿå¿ƒè·³ | è¿è¡ŒçŠ¶æ€æ­£å¸¸\n\
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\
            â–¶ è¿è¡Œæ—¶é•¿: {:.1} å°æ—¶\n\
            â–¶ å¤„ç†åŒºå—: {}\n\
            â–¶ ç›‘æ§ä»£å¸: {}\n\
            â–¶ èŠ‚ç‚¹çŠ¶æ€: {}/{} æ­£å¸¸\n\
            â–¶ æœ€åå¼‚å¸¸: {}",
            state.start_time.elapsed().unwrap().as_secs_f64() / 3600.0,
            metrics.processed_blocks,
            state.processed_tokens,
            self.rpc_pool.health_status.iter().filter(|v| *v.value()).count(),
            self.rpc_pool.clients.len(),
            chrono::Local::now().format("%Y-%m-%d %H:%M:%S")
        );

        for key in &self.config.serverchan.keys {
            if let Err(e) = self.send_server_chan(key, &message, "heartbeat").await {
                log::error!("å¿ƒè·³æ¨é€å¤±è´¥: {}", e);
            }
        }
    }

    pub fn generate_risk_alert(&self, analysis: &TokenAnalysis) -> String {
        // èµ„é‡‘æµæ ¼å¼åŒ–
        let fund_flows = analysis.fund_flows.iter().enumerate().map(|(i, flow)| {
            let arrow = "â†‘".repeat(3);
            let flow_type = match flow.risk_level {
                0..=30 => "âœ… ä½é£é™©èµ„é‡‘",
                31..=70 => "âš ï¸ ä¸­ç­‰é£é™©",
                _ => "ğŸš¨ é«˜é£é™©èµ„é‡‘"
            };
            
            format!(
                "â”£â” èµ„é‡‘é“¾#{} ({:.2} SOL) - {}\nâ”ƒ   {}\nâ”ƒ   {} â”” {}\nâ”ƒ   {} â”” {}",
                i+1,
                flow.amount,
                flow_type,
                flow.destination_wallet,
                arrow,
                flow.intermediate_wallet,
                arrow,
                flow.source_wallet
            )
        }).collect::<Vec<_>>().join("\n");

        // åˆ›å»ºè€…å†å²æ ¼å¼åŒ–
        let creator_history = analysis.creator_projects.iter().map(|p| {
            format!(
                "â”ƒ   â”£â” {}. {}: ${:.1}M ({})",
                p.index, p.name, p.market_cap, p.date
            )
        }).collect::<Vec<_>>().join("\n");

        // æŒå¸åˆ†å¸ƒæ ¼å¼åŒ–
        let holder_distribution = analysis.holder_distribution.iter().map(|(category, percent)| {
            format!("â”£â” {}: {:.1}%", category, percent)
        }).collect::<Vec<_>>().join("\n");

        format!(
            r#"ğŸš¨ é«˜é£é™©ä»£å¸é¢„è­¦ - éœ€è¦ç‰¹åˆ«å…³æ³¨!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ”” æ·±åº¦åˆ†ææŠ¥å‘Š (UTC+8) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“

ğŸ“‹ åŸºç¡€ä¿¡æ¯
â”£â” ä»£å¸: {} ({})
â”£â” åˆçº¦: {} ğŸ“‹
â”—â” åˆ›å»ºè€…: {} ğŸ“‹

ğŸ’° ä»£å¸æ•°æ®
â”£â” å‘è¡Œé‡: {} | åˆå§‹ä»·æ ¼: ${} | å½“å‰ä»·æ ¼: ${}
â”£â” å½“å‰å¸‚å€¼: ${:.1}M | æµåŠ¨æ€§: {} SOL | æ¶¨å¹…: +{:.1}%
â”—â” é”å®šè¯¦æƒ…: {} | æŒæœ‰äºº: {} | é›†ä¸­åº¦: {:.1}%

ğŸ’¸ èµ„é‡‘è¿½æº¯ (æ€»æµå…¥: {:.2} SOL)
{}

ğŸ“Š åˆ›å»ºè€…åˆ†æ
â”£â” å†å²æ•°æ®: é¡¹ç›®æ€»æ•°: {}ä¸ª | æˆåŠŸ: {}ä¸ª({:.1}%) | é«˜é£é™©é¡¹ç›®: {}ä¸ª
â”£â” ä»£å¸åˆ—è¡¨:
{}
â”—â” ç»¼åˆæŒ‡æ ‡: å¹³å‡å¸‚å€¼: ${:.2}M | ä¿¡ç”¨è¯„åˆ†: {}

âš ï¸ é£é™©è¯„ä¼° (é£é™©è¯„åˆ†: {}/100)
â”£â” é«˜é£é™©ä¿¡å·:
â”ƒ   â”£â” {} 
â”ƒ   â”—â” {}
â”£â” ä¸­ç­‰é£é™©:
â”ƒ   â”£â” {}
â”ƒ   â”—â” {}
â”—â” ç§¯æå› ç´ :
    â”£â” {}
    â”—â” {}

ğŸ“± ç¤¾äº¤åª’ä½“ & å¸‚åœºè¡¨ç°
â”£â” ç¤¾äº¤æ•°æ®: Twitter({},+{:.1}%) | Discord({},{:.1}%æ´»è·ƒ) | TG({})
â”£â” ä»·æ ¼å˜åŠ¨: 1h(+{:.1}%) | 24h(+{:.1}%) | é¦–æ¬¡äº¤æ˜“(+{:.1}%)
â”—â” äº¤æ˜“æ•°æ®: 24hé‡(${:.1}M) | ä¹°å‹({:.1}%) | å–å‹({:.1}%) | æµåŠ¨æ€§å˜åŒ–(+{:.1}%)

ğŸ‘¥ æŒå¸åˆ†å¸ƒ
{}
â”—â” é‡è¦åœ°å€: {}ä¸ªäº¤æ˜“æ‰€ | {}ä¸ªå¤§æˆ· | {}ä¸ªåšå¸‚å•†

ğŸ”— å¿«é€Ÿé“¾æ¥ (ç‚¹å‡»å¤åˆ¶)
â”£â” Birdeye: {}
â”£â” Solscan: {}
â”—â” åˆ›å»ºè€…: {}

â° ç›‘æ§ä¿¡æ¯
â”£â” å…³é”®æ—¶é—´: å‘ç°({}) | é¦–äº¤æ˜“({}) | æµåŠ¨æ€§æ·»åŠ ({})
â”£â” ç›‘æ§ç¼–å·: {} | é£é™©ç­‰çº§: {}
â”—â” ä¸‹æ¬¡æ›´æ–°: {}åˆ†é’Ÿå | å½“å‰çŠ¶æ€: {}

ğŸ’¡ é£é™©æç¤º
{}
"#,
            analysis.name,
            analysis.symbol,
            self.format_short_address(&analysis.mint),
            self.format_short_address(&analysis.creator),
            analysis.total_supply,
            analysis.initial_price,
            analysis.current_price,
            analysis.market_cap / 1_000_000.0,
            analysis.liquidity,
            analysis.price_change_24h * 100.0,
            analysis.lock_details,
            analysis.holder_count,
            analysis.holder_concentration * 100.0,
            analysis.total_inflow,
            fund_flows,
            analysis.creator_project_count,
            analysis.creator_success_count,
            (analysis.creator_success_count as f64 / analysis.creator_project_count as f64) * 100.0,
            analysis.creator_high_risk_count,
            creator_history,
            analysis.creator_avg_market_cap / 1_000_000.0,
            analysis.creator_credit_rating,
            analysis.risk_score,
            analysis.high_risk_factors[0],
            analysis.high_risk_factors[1],
            analysis.medium_risk_factors[0],
            analysis.medium_risk_factors[1],
            analysis.positive_factors[0],
            analysis.positive_factors[1],
            analysis.social.twitter_followers,
            analysis.social.twitter_growth * 100.0,
            analysis.social.discord_members,
            analysis.social.discord_activity * 100.0,
            analysis.social.telegram_members,
            analysis.price_change_1h * 100.0,
            analysis.price_change_24h * 100.0,
            analysis.initial_price_change * 100.0,
            analysis.volume_24h / 1_000_000.0,
            analysis.buy_pressure * 100.0,
            analysis.sell_pressure * 100.0,
            analysis.liquidity_change * 100.0,
            holder_distribution,
            analysis.exchange_wallets,
            analysis.whale_wallets,
            analysis.market_makers,
            format!("birdeye.so/token/{}", analysis.mint),
            format!("solscan.io/token/{}", analysis.mint),
            format!("solscan.io/account/{}", analysis.creator),
            analysis.detection_time.format("%m-%d %H:%M"),
            analysis.first_trade_time.format("%m-%d %H:%M"),
            analysis.liquidity_add_time.format("%m-%d %H:%M"),
            analysis.monitor_id,
            analysis.risk_level,
            analysis.next_update_minutes,
            analysis.monitoring_status,
            analysis.risk_advice
        )
    }

    fn format_short_address(&self, address: &Pubkey) -> String {
        let addr_str = address.to_string();
        format!("{}...{}", &addr_str[..4], &addr_str[addr_str.len()-4..])
    }
}

//===========================================
// è¾…åŠ©æ•°æ®ç»“æ„
//===========================================
#[derive(Debug)]
struct TokenMetrics {
    supply_score: f64,
    liquidity_score: f64,
    holder_score: f64,
    risk_score: f64,
    market_cap: f64,
    price: f64,
    verified: bool,
}

#[derive(Debug, Deserialize)]
struct TokenResponse {
    data: TokenData,
}

#[derive(Debug, Deserialize)]
struct TokenData {
    mint: Pubkey,
    name: String,
    symbol: String,
    market_cap: f64,
    liquidity: f64,
    holder_count: u64,
    holder_concentration: f64,
    verified: bool,
    price: f64,
    supply: u64,
    creator: Pubkey,
}

#[derive(Debug, Deserialize)]
struct AddressActivityResponse {
    data: ActivityData,
}

#[derive(Debug, Deserialize)]
struct ActivityData {
    items: Vec<ActivityItem>,
}

#[derive(Debug, Deserialize)]
struct ActivityItem {
    source: Pubkey,
    amount: f64,
    timestamp: u64,
    signature: String,
}

#[derive(Debug, Deserialize)]
struct TokenListResponse {
    data: TokenListData,
}

#[derive(Debug, Deserialize)]
struct TokenListData {
    items: Vec<TokenListItem>,
    total: u64,
}

#[derive(Debug, Deserialize)]
struct TokenListItem {
    address: Pubkey,
    symbol: String,
    name: String,
    market_cap: f64,
    created_at: u64,
}

#[derive(Debug)]
pub struct LoadMetrics {
    pub cpu_usage: AtomicF64,
    pub memory_usage: AtomicF64,
}

impl Default for LoadMetrics {
    fn default() -> Self {
        Self {
            cpu_usage: AtomicF64::new(0.0),
            memory_usage: AtomicF64::new(0.0),
        }
    }
}

#[derive(Debug)]
pub struct RpcMetrics {
    pub requests: AtomicUsize,
    pub errors: AtomicUsize,
    pub latency: AtomicF64,
}

impl Default for RpcMetrics {
    fn default() -> Self {
        Self {
            requests: AtomicUsize::new(0),
            errors: AtomicUsize::new(0),
            latency: AtomicF64::new(0.0),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_token_analysis() {
        let monitor = TokenMonitor::new().await.unwrap();
        let mint = Pubkey::new_unique();
        let creator = Pubkey::new_unique();
        
        let analysis = monitor.analyze_token(&mint, &creator).await.unwrap();
        assert!(analysis.risk_score <= 100);
    }

    #[test]
    fn test_risk_score_calculation() {
        // æ·»åŠ é£é™©è¯„åˆ†è®¡ç®—çš„æµ‹è¯•
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    env_logger::init();
    
    // åˆ›å»ºç›‘æ§å®ä¾‹
    let monitor = TokenMonitor::new().await?;
    
    // æ³¨å†Œä¿¡å·å¤„ç†
    let running = monitor.service_state.running.clone();
    ctrlc::set_handler(move || {
        running.store(false, Ordering::SeqCst);
    })?;
    
    // å¯åŠ¨æœåŠ¡
    monitor.start_service().await?;
    
    // ç­‰å¾…æœåŠ¡åœæ­¢
    while monitor.service_state.running.load(Ordering::SeqCst) {
        tokio::time::sleep(Duration::from_secs(1)).await;
    }
    
    // æ¸…ç†èµ„æº
    monitor.stop_service().await?;
    
    Ok(())
} 
